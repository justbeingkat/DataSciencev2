{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "5.3.1 Text Classification\n",
    "• Design and implement a system to recommend a conference to a researcher given the title of his new article.\n",
    "• The system should use the provided Conference Proceedings training data. You should implement the sub-tasks (feature extraction, dimensionality reduction, and classifier) by yourself.\n",
    "• You are free to select the algorithms you prefer for each sub-task. However, it is recommended that you test and compare multiple methods.\n",
    "• Evaluate you system on the training set by using the cross-validation approach. Provide the confusion\n",
    "matrix of your system output.\n",
    "• Evaluation should be done in terms of Micro-average precision, recall and F1 measures.\n",
    "• Once you found the best model on the training set, evaluate your model on the test set and report the\n",
    "results."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26b33ef2b8a38761"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-23T09:58:01.950735Z",
     "start_time": "2024-01-23T09:58:01.943663Z"
    }
   },
   "id": "initial_id",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('DBLPTrainset.txt', sep='\\t', header=None, names=['ID', 'Conference', 'Title'])\n",
    "test_data = pd.read_csv('DBLPTestset.txt', sep='\\t', header=None, names=['ID', 'Title'])\n",
    "ground_truth_labels = pd.read_csv('DBLPTestGroundTruth.txt', sep='\\t', header=None, names=['ID', 'Conference'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T09:46:37.374384Z",
     "start_time": "2024-01-23T09:46:37.296971Z"
    }
   },
   "id": "926ea59326c1df4d",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization for both training and test sets\n",
    "tfidf_Vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf_Vectorizer.fit_transform(train_data['Title'])\n",
    "y_train = train_data['Conference']\n",
    "\n",
    "X_test_tfidf = tfidf_Vectorizer.transform(test_data['Title'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T09:55:56.302702Z",
     "start_time": "2024-01-23T09:55:55.804160Z"
    }
   },
   "id": "d0051bdafe57b587",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Feature Extraction - Word Embeddings (Word2Vec)\n",
    "word2vec_model = Word2Vec(sentences=train_data['Title'].apply(str.split), vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def get_word_vector(words):\n",
    "    vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "X_train_word2vec = pd.DataFrame([get_word_vector(words) for words in train_data['Title'].apply(str.split)])\n",
    "X_test_word2vec = pd.DataFrame([get_word_vector(words) for words in test_data['Title'].apply(str.split)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T09:54:01.910329Z",
     "start_time": "2024-01-23T09:53:57.846218Z"
    }
   },
   "id": "ae9e9fb4f4f1651c",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store results\n",
    "results = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T10:04:51.035202Z",
     "start_time": "2024-01-23T10:04:51.026815Z"
    }
   },
   "id": "f718be3bfe1d6d5a",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# SVM with TF-IDF\n",
    "svm_tfidf_classifier = SVC(kernel='linear', C=1.0)\n",
    "svm_tfidf_classifier.fit(X_train_tfidf, train_data['Conference'])\n",
    "y_pred_test_svm_tfidf = svm_tfidf_classifier.predict(X_test_tfidf)\n",
    "accuracy_svm_tfidf = accuracy_score(ground_truth_labels['Conference'], y_pred_test_svm_tfidf)\n",
    "results.append({'Features': 'TF-IDF', 'Classifier': 'SVM', 'Accuracy': accuracy_svm_tfidf})"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-23T10:04:52.078938Z"
    }
   },
   "id": "ccecb20dc47f7558",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5b137a5cba9943f6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Combine test data with predicted labels and ground truth labels\n",
    "evaluation_data = pd.DataFrame({'ID': test_data['ID'], 'Predicted_Conference_Label': y_pred_test})\n",
    "evaluation_data = pd.merge(evaluation_data, ground_truth_labels, on='ID')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T09:47:21.003435Z",
     "start_time": "2024-01-23T09:47:20.980650Z"
    }
   },
   "id": "bd7c172a4c154c32",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.8639193596205159\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = (evaluation_data['Predicted_Conference_Label'] == evaluation_data['Conference']).mean()\n",
    "print(f\"Accuracy on the test set: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-23T09:47:21.006600Z",
     "start_time": "2024-01-23T09:47:20.998758Z"
    }
   },
   "id": "71a437dbb15938dc",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "5.3.2 Named Entity Recognition\n",
    "• Design and implement a system to extract and classify named entities in tweets.\n",
    "• The system should use the provided NER Twitter training data. You should implement the sub-tasks (feature extraction, and classifier) by yourself.\n",
    "• You are free to select the algorithms you prefer for each sub-task. However, it is recommended that you test and compare multiple methods.\n",
    "• Evaluate you system on the training set by using the cross-validation approach.\n",
    "• Evaluation should be done in terms of micro-average of precision, recall and F1 measures.\n",
    "• Evaluate your best model you found on the training set on the test set. Report your results."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d21f386fe97a4843"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
